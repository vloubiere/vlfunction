% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ChIP_CUT&RUN_pipeline.R
\name{vl_CUTNRUN_processing}
\alias{vl_CUTNRUN_processing}
\title{CUTNRUN pipeline}
\usage{
vl_CUTNRUN_processing(
  metadata,
  processed_metadata_output,
  fq_output_folder = "/scratch/stark/vloubiere/fq/CUTNRUN/",
  bam_output_folder = "/scratch/stark/vloubiere/bam/CUTNRUN/",
  alignment_stats_output_folder = "db/alignment_stats/CUTNRUN/",
  tmp_folder = "/scratch/stark/vloubiere/CUTNRUN/tmp/sort/",
  cores = 8,
  mem = 64,
  overwrite = FALSE,
  submit = FALSE,
  wdir = getwd(),
  logs = "db/logs/CUTNRUN/processing",
  time = "1-00:00:00"
)
}
\arguments{
\item{metadata}{The path to a correctly formatted .xlsx. .rds or .txt metadata file, or a data.table.
See the template at '/groups/stark/vloubiere/projects/vl_pipelines/Rdata/metadata_CutNRun.xlsx'.}

\item{processed_metadata_output}{An .rds path where to save the processed metadata file, which contains the paths of all output files and will be used to manage them.
By default, when importing the metadata from an excel sheet, "_processed.rds" will be appended to the excel file path.}

\item{fq_output_folder}{Output folder for .fq files. Default= "/scratch/stark/vloubiere/fq/CUTNRUN/".}

\item{bam_output_folder}{Output folder for .bam aligned files. Default= "/scratch/stark/vloubiere/bam/CUTNRUN/".}

\item{alignment_stats_output_folder}{Output folder for alignment statistics. Default= "db/alignment_stats/CUTNRUN/".}

\item{tmp_folder}{Temporary folder to store bam files during sorting. Default= "/scratch/star/vloubiere/CUTNRUN/tmp/sort/"}

\item{cores}{Number of cores per job. Default= 8.}

\item{mem}{Memory per job (in Go). Default= 32.}

\item{overwrite}{Should existing files be overwritten?}

\item{submit}{Should the command be submitted? Default= FALSE.}

\item{wdir}{The working directory to use. Default= getwd(), meaning current working directory will be used.}

\item{logs}{Output folder for log files. Default= "db/logs/CUTNRUN/processing".}

\item{time}{The time required for the SLURM scheduler. Default= '1-00:00:00'.}
}
\value{
Return a data.table containing, for each sampleID, the concatenated commands that are required to process the data.
These commands can then be submitted either directly via the function, or using vl_bsub()....
}
\description{
To use this this pipeline, please install the vl_function package using install_github("vloubiere/vlfunction")
in your interactive Rstudio session AND in the local installation of R 4.3.0 ('/software/f2022/software/r/4.3.0-foss-2022b/bin/R') 
which will be used to submit R sub-script.
}
\details{
The pipeline is split into two main functions. The first vl_CUTNRUN_processing() function aligns the reads and filters confident alignments.
It takes as input a (correctly formatted) metadata file, saves the processed metadata file and returns and/or submit the command lines to: \cr
1/ extract reads from VBC .bam file. Output .fq files are saved tmp_folder/fq/\cr
2/ trim the reads. Output .fq files are saved in tmp_folder/fq/ \cr
3/ aligns them to mouse/human genome (see 'genome' column of the metadata table). Output .bam files are saved in tmp_folder/bam/ \cr
4/ return alignment statistics. Output .txt files are saved in alignment_stats_output_folder/ \cr
5/ return mapq30_statistics (confidently aligned reads). Output .txt files are saved in alignment_stats_output_folder/ \cr

The second function, vl_CUTNRUN_peakCalling(), takes care of the peak calling, and returns and/or submit the command lines to: \cr
1/ peaks for each replicate. Output .narrowpeak files are saved in peaks_output_folder/ \cr
2/ .bw tracks for each replicate. Output .bw files are saved in bw_output_folder/ \cr
3/ Peaks called on the merged replicates. Output .narrowpeak files are saved in peaks_output_folder/ \cr
4/ .bw tracks using merged replicates. Output .bw files are saved in bw_output_folder/ \cr
5/ Confident peaks that are detected using merged reads but also each individual replicate. Output .narrowpeak files are saved in peaks_output_folder/ \cr
}
\examples{
# Process example dataset ----
library(vlfunctions)

# Example metadata ----
metadata <- system.file("CUTNRUN_pipeline", "metadata_CutNRun.xlsx", package = "vlfunctions")

# Generate commands ----
cmd <- vl_CUTNRUN_processing(metadata = metadata,
                             overwrite= TRUE,
                             submit= FALSE)
                             
# To submit, switch to submit= TRUE ----
vl_CUTNRUN_processing(metadata = metadata,
                      processed_metadata_output = "Rdata/metadata_CutNRun_processed.rds",
                      overwrite= FALSE, # Existing files will not be processed again
                      submit= TRUE)
                      
# Peak calling 
see ?vl_CUTNRUN_peakCalling()

}
