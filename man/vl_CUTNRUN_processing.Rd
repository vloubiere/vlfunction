% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ChIP_CUT&RUN_pipeline.R
\name{vl_CUTNRUN_processing}
\alias{vl_CUTNRUN_processing}
\title{ORFtag pipeline}
\usage{
vl_CUTNRUN_processing(
  metadata,
  processed_metadata_output,
  scratch_folder = "/scratch/stark/vloubiere/CUTNRUN",
  cores = 8,
  mem = 64,
  overwrite = F,
  submit = F,
  wdir = getwd(),
  logs = "db/logs/CUTNRUN/processing",
  time = "1-00:00:00"
)
}
\arguments{
\item{metadata}{The path to a .txt, tab-separated metadata file containing at least 12 columns. See vlfunctions::vl_metadata_ORFtag for an example.}

\item{processed_metadata_output}{An .rds path where to save the processed metadata file (containing the paths of output files).}

\item{scratch_folder}{Folder where intermediate bam and fastq files will be saved}

\item{cores}{Number of cores per job. Default= 8}

\item{mem}{Memory per job (in Go). Default= 32.}

\item{overwrite}{Should existing files be overwritten?}

\item{submit}{Should the command be submitted? default= G}

\item{wdir}{The working directory to use. defaut= getwd().}

\item{logs}{Path to save logs. Default= "db/logs/CUTNRUN/processing"}

\item{time}{The time required for the SLURM scheduler. Default= '1-00:00:00'}
}
\value{
Return a data.table containing, for each sampleID, the concatenated commands that are required to process the data. These commands can then be submitted using ?vl_bsub().
}
\description{
Takes as input a (corerectly formated) metadata file, save the processed metadata file and returns the command lines to 1/ extract reads from VBC bam file, 2/ trim the reads and align to mouse/human genome (see 'species' column of the metadata table) and return alignment statistics as well as collapsed reads and 4/ assign insertions to closest downstream genes.
}
\examples{
Takes as input a .xlsx metadata sheet that should be formatted as follows:
>>>>
READ ME																									
sampleID should be the concatenation of ab, cell_line, treatment, experiment and replicate; and should be unique for each sample/replicate. Samples with the same sampleID will be merged (re-sequencing...).																									
The condition should be shared between replicates, and will be used to call peaks on the merge data.																									
The input column should specify the replicate-matched input sampleID.																									
user	method	experiment	antibody	cell_line	treatment	replicate	condition	sampleID	barcode	i5	genome	input	layout	sequencer	bam_path
<<<<
custom extra columns are tolerated						

Print command lines for all samples without submitting the jobs:
check <- vl_CUTNRUN_processing(metadata = "/groups/stark/nemcko/Hcfc1_paper/Hcfc1_new/Rdata/metadata_CutNRun.xlsx",
                               processed_metadata_output = "Rdata/CUTNRUN_metadata_processed.rds",
                               overwrite = T,
                               submit = F)

Run the pipeline without overwriting existing files:
vl_CUTNRUN_processing(metadata = "/groups/stark/nemcko/Hcfc1_paper/Hcfc1_new/Rdata/metadata_CutNRun.xlsx",
                      processed_metadata_output = "Rdata/CUTNRUN_metadata_processed.rds",
                      overwrite = F,
                      submit = T)
                      
}
